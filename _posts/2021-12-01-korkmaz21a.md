---
title: Investigating vulnerabilities of deep neural policies
abstract: Reinforcement learning policies based on deep neural networks are vulnerable
  to imperceptible adversarial perturbations to their inputs, in much the same way
  as neural network image classifiers. Recent work has proposed several methods to
  improve the robustness of deep reinforcement learning agents to adversarial perturbations
  based on training in the presence of these imperceptible perturbations (i.e. adversarial
  training). In this paper, we study the effects of adversarial training on the neural
  policy learned by the agent. In particular, we follow two distinct parallel approaches
  to investigate the outcomes of adversarial training on deep neural policies based
  on worst-case distributional shift and feature sensitivity. For the first approach,
  we compare the Fourier spectrum of minimal perturbations computed for both adversarially
  trained and vanilla trained neural policies. Via experiments in the OpenAI Atari
  environments we show that minimal perturbations computed for adversarially trained
  policies are more focused on lower frequencies in the Fourier domain, indicating
  a higher sensitivity of these policies to low frequency perturbations. For the second
  approach, we propose a novel method to measure the feature sensitivities of deep
  neural policies and we compare these feature sensitivity differences in state-of-the-art
  adversarially trained deep neural policies and vanilla trained deep neural policies.
  We believe our results can be an initial step towards understanding the relationship
  between adversarial training and different notions of robustness for neural policies.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: korkmaz21a
month: 0
tex_title: Investigating vulnerabilities of deep neural policies
firstpage: 1661
lastpage: 1670
page: 1661-1670
order: 1661
cycles: false
bibtex_author: Korkmaz, Ezgi
author:
- given: Ezgi
  family: Korkmaz
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/korkmaz21a/korkmaz21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/korkmaz21a/korkmaz21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
