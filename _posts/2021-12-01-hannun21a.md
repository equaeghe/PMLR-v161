---
title: Measuring data leakage in machine-learning models with Fisher information
abstract: Machine-learning models contain information about the data they were trained
  on. This information leaks either through the model itself or through predictions
  made by the model. Consequently, when the training data contains sensitive attributes,
  assessing the amount of information leakage is paramount. We propose a method to
  quantify this leakage using the Fisher information of the model about the data.
  Unlike the worst-case <em>a priori</em> guarantees of differential privacy, <em>Fisher
  information loss</em> measures leakage with respect to specific examples, attributes,
  or sub-populations within the dataset. We motivate Fisher information loss through
  the Cram\â€™{e}r-Rao bound and delineate the implied threat model. We provide efficient
  methods to compute Fisher information loss for output-perturbed generalized linear
  models. Finally, we empirically validate Fisher information loss as a useful measure
  of information leakage.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hannun21a
month: 0
tex_title: Measuring data leakage in machine-learning models with Fisher information
firstpage: 760
lastpage: 770
page: 760-770
order: 760
cycles: false
bibtex_author: Hannun, Awni and Guo, Chuan and van der Maaten, Laurens
author:
- given: Awni
  family: Hannun
- given: Chuan
  family: Guo
- given: Laurens
  family: Maaten
  prefix: van der
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/hannun21a/hannun21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/hannun21a/hannun21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
