---
title: 'Path-BN: Towards effective batch normalization in the Path Space for ReLU
  networks'
abstract: Neural networks with ReLU activation functions (abbrev. ReLU Networks),
  have demonstrated their success in many applications. Recently, researchers noticed
  that ReLU networks are positively scale-invariant (PSI) while the weights are not.
  This mismatch may lead to undesirable behaviors in the optimization process. Hence,
  some new algorithms that conduct optimization directly in the <em>path space</em>
  (the path space is proven to be PSI) were developed, such as Stochastic Gradient
  Descent (SGD) in the path space. %nd it was shown that, SGD in the path space is
  superior to that in the weight space. However, it is still unknown that whether
  other deep learning techniques such as batch normalization (BN), could also have
  their counterparts in the path space. In this paper, we conduct a formal study on
  the design of BN in the path space. First, we propose <em>path-reparameterization</em>
  of ReLU networks, in which the weights in the networks are reparameterized by path-values.
  Then, the feedforward and backward propagation of the path-reparameterized networks
  can calculate the values of the hidden nodes and the gradients in the path space,
  respectively. Next, we design the a novel way to do batch normalization for the
  path-reparameterized ReLU networks, called <em>Path-BN</em>. Specifically, we notice
  that, path-reparameterized ReLU NNs have a portion of constant weights which play
  more critical roles to form the basis of the path space. We propose to exclude these
  constant weights when doing batch normalization and prove that, by doing so, the
  scale and the direction of the trained parameters can be more effectively decoupled
  during training. Finally, we conduct experiments on benchmark datasets. The results
  show that our proposed Path-BN can improve the performance of the optimization algorithms
  in the path space.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: luo21b
month: 0
tex_title: 'Path-BN: Towards effective batch normalization in the Path Space for ReLU
  networks'
firstpage: 834
lastpage: 843
page: 834-843
order: 834
cycles: false
bibtex_author: Luo, Xufang and Meng, Qi and Chen, Wei and Wang, Yunhong and Liu, Tie-Yan
author:
- given: Xufang
  family: Luo
- given: Qi
  family: Meng
- given: Wei
  family: Chen
- given: Yunhong
  family: Wang
- given: Tie-Yan
  family: Liu
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/luo21b/luo21b.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/luo21b/luo21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
