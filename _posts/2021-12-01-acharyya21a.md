---
title: Statistical mechanical analysis of neural network pruning
abstract: Deep learning architectures with a huge number of parameters are often compressed
  using <em>pruning</em> techniques to ensure computational efficiency of inference
  during deployment. Despite multitude of empirical advances, there is a lack of theoretical
  understanding of the effectiveness of different pruning methods. We inspect different
  pruning techniques under the statistical mechanics formulation of a teacher-student
  framework and derive their generalization error (GE) bounds. It has been shown that
  <em>Determinantal Point Process</em> (DPP) based <em>node</em> pruning method is
  notably superior to competing approaches when tested on real datasets. Using GE
  bounds in the aforementioned setup we provide theoretical guarantees for their empirical
  observations. Another consistent finding in literature is that sparse neural networks
  (<em>edge pruned</em>) generalize better than dense neural networks (<em>node pruned</em>)
  for a fixed number of parameters. We use our theoretical setup to prove this finding
  and show that even the baseline <em>random edge pruning</em> method performs better
  than the <em>DPP node pruning</em> method. We also validate this empirically on
  real datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: acharyya21a
month: 0
tex_title: Statistical mechanical analysis of neural network pruning
firstpage: 1988
lastpage: 1997
page: 1988-1997
order: 1988
cycles: false
bibtex_author: Acharyya, Rupam and Chattoraj, Ankani and Zhang, Boyu and Das, Shouman
  and \v{S}tefankovi\v{c}, Daniel
author:
- given: Rupam
  family: Acharyya
- given: Ankani
  family: Chattoraj
- given: Boyu
  family: Zhang
- given: Shouman
  family: Das
- given: Daniel
  family: Štefankovič
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/acharyya21a/acharyya21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/acharyya21a/acharyya21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
