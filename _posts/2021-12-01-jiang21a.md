---
title: 'TreeBERT: A tree-based pre-trained model for programming language'
abstract: Source code can be parsed into the abstract syntax tree (AST) based on defined
  syntax rules. However, in pre-training, little work has considered the incorporation
  of tree structure into the learning process. In this paper, we present TreeBERT,
  a tree-based pre-trained model for improving programming language-oriented generation
  tasks. To utilize tree structure, TreeBERT represents the AST corresponding to the
  code as a set of composition paths and introduces node position embedding. The model
  is trained by tree masked language modeling (TMLM) and node order prediction (NOP)
  with a hybrid objective. TMLM uses a novel masking strategy designed according to
  the treeâ€™s characteristics to help the model understand the AST and infer the missing
  semantics of the AST. With NOP, TreeBERT extracts the syntactical structure by learning
  the order constraints of nodes in AST. We pre-trained TreeBERT on datasets covering
  multiple programming languages. On code summarization and code documentation tasks,
  TreeBERT outperforms other pre-trained models and state-of-the-art models designed
  for these tasks. Furthermore, TreeBERT performs well when transferred to the pre-trained
  unseen programming language.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jiang21a
month: 0
tex_title: 'TreeBERT: A tree-based pre-trained model for programming language'
firstpage: 54
lastpage: 63
page: 54-63
order: 54
cycles: false
bibtex_author: Jiang, Xue and Zheng, Zhuoran and Lyu, Chen and Li, Liang and Lyu,
  Lei
author:
- given: Xue
  family: Jiang
- given: Zhuoran
  family: Zheng
- given: Chen
  family: Lyu
- given: Liang
  family: Li
- given: Lei
  family: Lyu
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/jiang21a/jiang21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/jiang21a/jiang21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
