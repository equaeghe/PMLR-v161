---
title: Post-hoc loss-calibration for Bayesian neural networks
abstract: Bayesian decision theory provides an elegant framework for acting optimally
  under uncertainty when tractable posterior distributions are available. Modern Bayesian
  models, however, typically involve intractable posteriors that are approximated
  with, potentially crude, surrogates. This difficulty has engendered loss-calibrated
  techniques that aim to learn posterior approximations that favor high-utility decisions.
  In this paper, focusing on Bayesian neural networks, we develop methods for correcting
  approximate posterior predictive distributions encouraging them to prefer high-utility
  decisions. In contrast to previous work, our approach is agnostic to the choice
  of the approximate inference algorithm, allows for efficient test time decision
  making through amortization, and empirically produces higher quality decisions.
  We demonstrate the effectiveness of our approach through controlled experiments
  spanning a diversity of tasks and datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: vadera21a
month: 0
tex_title: Post-hoc loss-calibration for Bayesian neural networks
firstpage: 1403
lastpage: 1412
page: 1403-1412
order: 1403
cycles: false
bibtex_author: Vadera, Meet P. and Ghosh, Soumya and Ng, Kenney and Marlin, Benjamin
  M.
author:
- given: Meet P.
  family: Vadera
- given: Soumya
  family: Ghosh
- given: Kenney
  family: Ng
- given: Benjamin M.
  family: Marlin
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/vadera21a/vadera21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/vadera21a/vadera21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
