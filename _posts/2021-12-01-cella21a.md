---
title: Multi-task and meta-learning with sparse linear bandits
abstract: Motivated by recent developments on meta-learning with linear contextual
  bandit tasks, we study the benefit of feature learning in both the multi-task and
  meta-learning settings. We focus on the case that the task weight vectors are <em>jointly
  sparse</em>, i.e. they share the same small set of predictive features. Starting
  from previous work on standard linear regression with the group-lasso estimator
  we provide novel oracle-inequalities for this estimator when samples are collected
  by a bandit policy. Subsequently, building on a recent lasso-bandit policy, we investigate
  its group-lasso variant and analyze its regret bound. We specialize the proposed
  policy to the multi-task and meta-learning settings, demonstrating its theoretical
  advantage. We also point out a deficiency in the state-of-the-art lower bound and
  observe that our method has a smaller upper bound. Preliminary experiments confirm
  the effectiveness of our approach in practice.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cella21a
month: 0
tex_title: Multi-task and meta-learning with sparse linear bandits
firstpage: 1692
lastpage: 1702
page: 1692-1702
order: 1692
cycles: false
bibtex_author: Cella, Leonardo and Pontil, Massimiliano
author:
- given: Leonardo
  family: Cella
- given: Massimiliano
  family: Pontil
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/cella21a/cella21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/cella21a/cella21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
