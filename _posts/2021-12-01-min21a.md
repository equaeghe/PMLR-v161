---
title: 'The curious case of adversarially robust models: More data can help, double
  descend, or hurt generalization'
abstract: Adversarial training has shown its ability in producing models that are
  robust to perturbations on the input data, but usually at the expense of a decrease
  in the standard accuracy. To mitigate this issue, it is commonly believed that more
  training data will eventually help such adversarially robust models generalize better
  on the benign/unperturbed test data. In this paper, however, we challenge this conventional
  belief and show that more training data can hurt the generalization of adversarially
  robust models in classification problems. We first investigate the Gaussian mixture
  classification with a linear loss and identify three regimes based on the strength
  of the adversary. In the weak adversary regime, more data improves the generalization
  of adversarially robust models. In the medium adversary regime, with more training
  data, the generalization loss exhibits a double descent curve, which implies the
  existence of an intermediate stage where more training data hurts the generalization.
  In the strong adversary regime, more data almost immediately causes the generalization
  error to increase. Then we analyze a two-dimensional classification problem with
  a 0-1 loss. We prove that more data always hurts generalization of adversarially
  trained models with large perturbations. Empirical studies confirm our theoretical
  results.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: min21a
month: 0
tex_title: 'The curious case of adversarially robust models: More data can help, double
  descend, or hurt generalization'
firstpage: 129
lastpage: 139
page: 129-139
order: 129
cycles: false
bibtex_author: Min, Yifei and Chen, Lin and Karbasi, Amin
author:
- given: Yifei
  family: Min
- given: Lin
  family: Chen
- given: Amin
  family: Karbasi
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/min21a/min21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/min21a/min21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
