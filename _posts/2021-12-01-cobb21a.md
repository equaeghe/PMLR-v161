---
title: Scaling Hamiltonian Monte Carlo inference for Bayesian neural networks with
  symmetric splitting
abstract: Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) approach
  that exhibits favourable exploration properties in high-dimensional models such
  as neural networks. Unfortunately, HMC has limited use in large-data regimes and
  little work has explored suitable approaches that aim to preserve the entire Hamiltonian.
  In our work, we introduce a new symmetric integration scheme for split HMC that
  does not rely on stochastic gradients. We show that our new formulation is more
  efficient than previous approaches and is easy to implement with a single GPU. As
  a result, we are able to perform full HMC over common deep learning architectures
  using entire data sets. In addition, when we compare with stochastic gradient MCMC,
  we show that our method achieves better performance in both accuracy and uncertainty
  quantification. Our approach demonstrates HMC as a feasible option when considering
  inference schemes for large-scale machine learning problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cobb21a
month: 0
tex_title: Scaling Hamiltonian Monte Carlo inference for Bayesian neural networks
  with symmetric splitting
firstpage: 675
lastpage: 685
page: 675-685
order: 675
cycles: false
bibtex_author: Cobb, Adam D. and Jalaian, Brian
author:
- given: Adam D.
  family: Cobb
- given: Brian
  family: Jalaian
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/cobb21a/cobb21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/cobb21a/cobb21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
