---
title: Probabilistic task modelling for meta-learning
abstract: We propose <em>probabilistic task modelling</em> â€“ a generative probabilistic
  model for collections of tasks used in meta-learning. The proposed model combines
  variational auto-encoding and latent Dirichlet allocation to model each task as
  a mixture of Gaussian distribution in an embedding space. Such modelling provides
  an explicit representation of a task through its task-theme mixture. We present
  an efficient approximation inference technique based on variational inference method
  for empirical Bayes parameter estimation. We perform empirical evaluations to validate
  the <em>task uncertainty</em> and <em>task distance</em> produced by the proposed
  method through correlation diagrams of the prediction accuracy on testing tasks.
  We also carry out experiments of task selection in meta-learning to demonstrate
  how the task relatedness inferred from the proposed model help to facilitate meta-learning
  algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nguyen21b
month: 0
tex_title: Probabilistic task modelling for meta-learning
firstpage: 781
lastpage: 791
page: 781-791
order: 781
cycles: false
bibtex_author: Nguyen, Cuong C. and Do, Thanh-Toan and Carneiro, Gustavo
author:
- given: Cuong C.
  family: Nguyen
- given: Thanh-Toan
  family: Do
- given: Gustavo
  family: Carneiro
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/nguyen21b/nguyen21b.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/nguyen21b/nguyen21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
