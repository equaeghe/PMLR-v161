---
title: Symmetric Wasserstein autoencoders
abstract: Leveraging the framework of Optimal Transport, we introduce a new family
  of generative autoencoders with a learnable prior, called Symmetric Wasserstein
  Autoencoders (SWAEs). We propose to symmetrically match the joint distributions
  of the observed data and the latent representation induced by the encoder and the
  decoder. The resulting algorithm jointly optimizes the modelling losses in both
  the data and the latent spaces with the loss in the data space leading to the denoising
  effect. With the symmetric treatment of the data and the latent representation,
  the algorithm implicitly preserves the local structure of the data in the latent
  space. To further improve the quality of the latent representation, we incorporate
  a reconstruction loss into the objective, which significantly benefits both the
  generation and reconstruction. We empirically show the superior performance of SWAEs
  over the state-of-the-art generative autoencoders in terms of classification, reconstruction,
  and generation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sun21a
month: 0
tex_title: Symmetric Wasserstein autoencoders
firstpage: 354
lastpage: 364
page: 354-364
order: 354
cycles: false
bibtex_author: Sun, Sun and Guo, Hongyu
author:
- given: Sun
  family: Sun
- given: Hongyu
  family: Guo
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/sun21a/sun21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/sun21a/sun21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
