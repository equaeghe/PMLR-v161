---
title: Learnable uncertainty under Laplace approximations
abstract: 'Laplace approximations are classic, computationally lightweight means for
  constructing Bayesian neural networks (BNNs). As in other approximate BNNs, one
  cannot necessarily expect the induced predictive uncertainty to be calibrated. Here
  we develop a formalism to explicitly “train” the uncertainty in a decoupled way
  to the prediction itself. To this end, we introduce <em>uncertainty units</em> for
  Laplace-approximated networks: Hidden units associated with a particular weight
  structure that can be added to any pre-trained, point-estimated network. Due to
  their weights, these units are inactive—they do not affect the predictions. But
  their presence changes the geometry (in particular the Hessian) of the loss landscape,
  thereby affecting the network’s uncertainty estimates under a Laplace approximation.
  We show that such units can be trained via an uncertainty-aware objective, improving
  standard Laplace approximations’ performance in various uncertainty quantification
  tasks.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kristiadi21a
month: 0
tex_title: Learnable uncertainty under Laplace approximations
firstpage: 344
lastpage: 353
page: 344-353
order: 344
cycles: false
bibtex_author: Kristiadi, Agustinus and Hein, Matthias and Hennig, Philipp
author:
- given: Agustinus
  family: Kristiadi
- given: Matthias
  family: Hein
- given: Philipp
  family: Hennig
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/kristiadi21a/kristiadi21a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v161/kristiadi21a/kristiadi21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
