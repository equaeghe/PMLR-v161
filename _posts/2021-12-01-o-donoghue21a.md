---
title: Matrix games with bandit feedback
abstract: We study a version of the classical zero-sum matrix game with unknown payoff
  matrix and bandit feedback, where the players only observe each others actions and
  a noisy payoff. This generalizes the usual matrix game, where the payoff matrix
  is known to the players. Despite numerous applications, this problem has received
  relatively little attention. Although adversarial bandit algorithms achieve low
  regret, they do not exploit the matrix structure and perform poorly relative to
  the new algorithms. The main contributions are regret analyses of variants of UCB
  and K-learning that hold for any opponent, e.g., even when the opponent adversarially
  plays the best-response to the learner’s mixed strategy. Along the way, we show
  that Thompson fails catastrophically in this setting and provide empirical comparison
  to existing algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: o-donoghue21a
month: 0
tex_title: Matrix games with bandit feedback
firstpage: 279
lastpage: 289
page: 279-289
order: 279
cycles: false
bibtex_author: O'Donoghue, Brendan and Lattimore, Tor and Osband, Ian
author:
- given: Brendan
  family: O’Donoghue
- given: Tor
  family: Lattimore
- given: Ian
  family: Osband
date: 2021-12-01
address:
container-title: Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial
  Intelligence
volume: '161'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 12
  - 1
pdf: https://proceedings.mlr.press/v161/o-donoghue21a/o-donoghue21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
